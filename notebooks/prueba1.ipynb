{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b885e941-d550-409d-a9ac-9f14cd4a5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37f9518-e4d3-4cd2-ad86-64bcc90aa240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_price</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>reviewer_rating</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>genre_ Action</th>\n",
       "      <th>genre_ Activities</th>\n",
       "      <th>genre_ Adult</th>\n",
       "      <th>genre_ Adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>were</th>\n",
       "      <th>what.1</th>\n",
       "      <th>when</th>\n",
       "      <th>which</th>\n",
       "      <th>who</th>\n",
       "      <th>will.1</th>\n",
       "      <th>with.1</th>\n",
       "      <th>would</th>\n",
       "      <th>you.1</th>\n",
       "      <th>your.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just Because</td>\n",
       "      <td>0.071516</td>\n",
       "      <td>-0.554055</td>\n",
       "      <td>A. Slater</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just Because</td>\n",
       "      <td>0.071516</td>\n",
       "      <td>-0.554055</td>\n",
       "      <td>A. Slater</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just Because</td>\n",
       "      <td>0.071516</td>\n",
       "      <td>-0.554055</td>\n",
       "      <td>A. Slater</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goodnight, Goodnight Construction Site (Board ...</td>\n",
       "      <td>-1.136580</td>\n",
       "      <td>1.358517</td>\n",
       "      <td>Margaret Zahalka</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goodnight, Goodnight Construction Site (Board ...</td>\n",
       "      <td>-1.136580</td>\n",
       "      <td>1.358517</td>\n",
       "      <td>Margaret Zahalka</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          book_title  book_price    rating  \\\n",
       "0                                       Just Because    0.071516 -0.554055   \n",
       "1                                       Just Because    0.071516 -0.554055   \n",
       "2                                       Just Because    0.071516 -0.554055   \n",
       "3  Goodnight, Goodnight Construction Site (Board ...   -1.136580  1.358517   \n",
       "4  Goodnight, Goodnight Construction Site (Board ...   -1.136580  1.358517   \n",
       "\n",
       "           reviewer  reviewer_rating  is_verified  genre_ Action  \\\n",
       "0         A. Slater                5            1          False   \n",
       "1         A. Slater                5            1          False   \n",
       "2         A. Slater                5            1          False   \n",
       "3  Margaret Zahalka                5            1          False   \n",
       "4  Margaret Zahalka                5            1          False   \n",
       "\n",
       "   genre_ Activities  genre_ Adult  genre_ Adventure  ...  were  what.1  when  \\\n",
       "0              False         False             False  ...   0.0     0.0   0.0   \n",
       "1              False         False             False  ...   0.0     0.0   0.0   \n",
       "2              False         False             False  ...   0.0     0.0   0.0   \n",
       "3              False         False             False  ...   0.0     0.0   0.0   \n",
       "4              False         False             False  ...   0.0     0.0   0.0   \n",
       "\n",
       "   which  who    will.1  with.1  would  you.1  your.1  \n",
       "0    0.0  0.0  0.222732     0.0    0.0    0.0     0.0  \n",
       "1    0.0  0.0  0.222732     0.0    0.0    0.0     0.0  \n",
       "2    0.0  0.0  0.222732     0.0    0.0    0.0     0.0  \n",
       "3    0.0  0.0  0.000000     0.0    0.0    0.0     0.0  \n",
       "4    0.0  0.0  0.000000     0.0    0.0    0.0     0.0  \n",
       "\n",
       "[5 rows x 323 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar los datasets\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataset para entender la estructura\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8541ab5c-5d0f-4bc1-bd63-74de99463e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A Court of Mist and Fury (A Court of Thorns and Roses, 2)</th>\n",
       "      <th>A Court of Thorns and Roses (A Court of Thorns and Roses, 1)</th>\n",
       "      <th>A Court of Thorns and Roses Paperback Box Set (5 books)</th>\n",
       "      <th>A Court of Wings and Ruin (A Court of Thorns and Roses, 3)</th>\n",
       "      <th>A Little Life</th>\n",
       "      <th>All the Light We Cannot See: A Novel</th>\n",
       "      <th>Atomic Habits: An Easy &amp; Proven Way to Build Good Habits &amp; Break Bad Ones</th>\n",
       "      <th>Brown Bear, Brown Bear, What Do You See?</th>\n",
       "      <th>Chicka Chicka Boom Boom (Board Book)</th>\n",
       "      <th>Demon Copperhead: A Pulitzer Prize Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Nonfiction</th>\n",
       "      <th>genre_Personal Finance</th>\n",
       "      <th>genre_Picture Book</th>\n",
       "      <th>genre_Picture Books</th>\n",
       "      <th>genre_Romance</th>\n",
       "      <th>genre_Self Help</th>\n",
       "      <th>genre_Self-improvement</th>\n",
       "      <th>genre_Spiritual Warfare</th>\n",
       "      <th>genre_Spirituality</th>\n",
       "      <th>genre_Thriller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A H Kobayashi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A. K. P.</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A. Slater</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.B.318</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.S.</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               A Court of Mist and Fury (A Court of Thorns and Roses, 2)  \\\n",
       "A H Kobayashi                                                NaN           \n",
       "A. K. P.                                                     NaN           \n",
       "A. Slater                                                    NaN           \n",
       "A.B.318                                                      NaN           \n",
       "A.S.                                                         NaN           \n",
       "\n",
       "               A Court of Thorns and Roses (A Court of Thorns and Roses, 1)  \\\n",
       "A H Kobayashi                                                NaN              \n",
       "A. K. P.                                                     NaN              \n",
       "A. Slater                                                    NaN              \n",
       "A.B.318                                                      NaN              \n",
       "A.S.                                                         NaN              \n",
       "\n",
       "               A Court of Thorns and Roses Paperback Box Set (5 books)  \\\n",
       "A H Kobayashi                                                NaN         \n",
       "A. K. P.                                                     NaN         \n",
       "A. Slater                                                    NaN         \n",
       "A.B.318                                                      NaN         \n",
       "A.S.                                                         NaN         \n",
       "\n",
       "               A Court of Wings and Ruin (A Court of Thorns and Roses, 3)  \\\n",
       "A H Kobayashi                                                NaN            \n",
       "A. K. P.                                                     NaN            \n",
       "A. Slater                                                    NaN            \n",
       "A.B.318                                                      NaN            \n",
       "A.S.                                                         NaN            \n",
       "\n",
       "               A Little Life  All the Light We Cannot See: A Novel  \\\n",
       "A H Kobayashi            NaN                                   NaN   \n",
       "A. K. P.                 NaN                                   NaN   \n",
       "A. Slater                NaN                                   NaN   \n",
       "A.B.318                  NaN                                   NaN   \n",
       "A.S.                     NaN                                   NaN   \n",
       "\n",
       "               Atomic Habits: An Easy & Proven Way to Build Good Habits & Break Bad Ones  \\\n",
       "A H Kobayashi                                                NaN                           \n",
       "A. K. P.                                                     NaN                           \n",
       "A. Slater                                                    NaN                           \n",
       "A.B.318                                                      NaN                           \n",
       "A.S.                                                         NaN                           \n",
       "\n",
       "               Brown Bear, Brown Bear, What Do You See?  \\\n",
       "A H Kobayashi                                       NaN   \n",
       "A. K. P.                                            NaN   \n",
       "A. Slater                                           NaN   \n",
       "A.B.318                                             NaN   \n",
       "A.S.                                                NaN   \n",
       "\n",
       "               Chicka Chicka Boom Boom (Board Book)  \\\n",
       "A H Kobayashi                                   NaN   \n",
       "A. K. P.                                        NaN   \n",
       "A. Slater                                       NaN   \n",
       "A.B.318                                         NaN   \n",
       "A.S.                                            NaN   \n",
       "\n",
       "               Demon Copperhead: A Pulitzer Prize Winner  ...  \\\n",
       "A H Kobayashi                                        NaN  ...   \n",
       "A. K. P.                                             NaN  ...   \n",
       "A. Slater                                            NaN  ...   \n",
       "A.B.318                                              NaN  ...   \n",
       "A.S.                                                 NaN  ...   \n",
       "\n",
       "               genre_Nonfiction  genre_Personal Finance  genre_Picture Book  \\\n",
       "A H Kobayashi               NaN                     NaN                 NaN   \n",
       "A. K. P.                    NaN                     NaN                 NaN   \n",
       "A. Slater                   NaN                     NaN                 NaN   \n",
       "A.B.318                     NaN                     NaN                 NaN   \n",
       "A.S.                        NaN                     NaN                 NaN   \n",
       "\n",
       "               genre_Picture Books  genre_Romance  genre_Self Help  \\\n",
       "A H Kobayashi                  NaN            NaN              NaN   \n",
       "A. K. P.                       NaN            NaN              NaN   \n",
       "A. Slater                      NaN            NaN              NaN   \n",
       "A.B.318                        NaN            NaN              NaN   \n",
       "A.S.                           NaN            NaN              NaN   \n",
       "\n",
       "               genre_Self-improvement  genre_Spiritual Warfare  \\\n",
       "A H Kobayashi                     NaN                      NaN   \n",
       "A. K. P.                          NaN                      NaN   \n",
       "A. Slater                         NaN                      NaN   \n",
       "A.B.318                           NaN                      NaN   \n",
       "A.S.                              NaN                      NaN   \n",
       "\n",
       "               genre_Spirituality  genre_Thriller  \n",
       "A H Kobayashi                 NaN             NaN  \n",
       "A. K. P.                      NaN             NaN  \n",
       "A. Slater                     NaN             NaN  \n",
       "A.B.318                       NaN             NaN  \n",
       "A.S.                          NaN             NaN  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear la matriz usuario-libro a partir de train_df\n",
    "user_book_matrix = train_df.pivot_table(index='reviewer', columns='book_title', values='reviewer_rating')\n",
    "\n",
    "# Calcular el promedio de calificaciones por cada libro\n",
    "book_rating_means = user_book_matrix.mean()\n",
    "\n",
    "# Llenar los valores faltantes con el promedio de las calificaciones del libro\n",
    "user_book_matrix_filled = user_book_matrix.apply(lambda row: row.fillna(book_rating_means))\n",
    "\n",
    "# Obtener las columnas que representan los géneros\n",
    "genre_columns = [col for col in train_df.columns if col.startswith('genre_')]\n",
    "\n",
    "# Crear una matriz que combine los géneros de los libros\n",
    "book_genres_matrix = train_df.groupby('book_title')[genre_columns].first()\n",
    "\n",
    "# Concatenar la matriz de géneros con la matriz de calificaciones de libros\n",
    "user_book_genre_matrix_filled = pd.concat([user_book_matrix_filled, book_genres_matrix], axis=1)\n",
    "\n",
    "# Revisar las primeras filas de la nueva matriz\n",
    "user_book_genre_matrix_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ce43aa-0a7b-465f-852e-1819496275a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A Court of Mist and Fury (A Court of Thorns and Roses, 2)</th>\n",
       "      <th>A Court of Thorns and Roses (A Court of Thorns and Roses, 1)</th>\n",
       "      <th>A Court of Thorns and Roses Paperback Box Set (5 books)</th>\n",
       "      <th>A Court of Wings and Ruin (A Court of Thorns and Roses, 3)</th>\n",
       "      <th>A Little Life</th>\n",
       "      <th>All the Light We Cannot See: A Novel</th>\n",
       "      <th>Atomic Habits: An Easy &amp; Proven Way to Build Good Habits &amp; Break Bad Ones</th>\n",
       "      <th>Brown Bear, Brown Bear, What Do You See?</th>\n",
       "      <th>Chicka Chicka Boom Boom (Board Book)</th>\n",
       "      <th>Demon Copperhead: A Pulitzer Prize Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Nonfiction</th>\n",
       "      <th>genre_Personal Finance</th>\n",
       "      <th>genre_Picture Book</th>\n",
       "      <th>genre_Picture Books</th>\n",
       "      <th>genre_Romance</th>\n",
       "      <th>genre_Self Help</th>\n",
       "      <th>genre_Self-improvement</th>\n",
       "      <th>genre_Spiritual Warfare</th>\n",
       "      <th>genre_Spirituality</th>\n",
       "      <th>genre_Thriller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A H Kobayashi</th>\n",
       "      <td>1.399516e-15</td>\n",
       "      <td>2.822698e-16</td>\n",
       "      <td>-1.270756e-15</td>\n",
       "      <td>1.020734e-15</td>\n",
       "      <td>6.168280e-17</td>\n",
       "      <td>1.161061e-30</td>\n",
       "      <td>3.458629e-17</td>\n",
       "      <td>1.310615e-15</td>\n",
       "      <td>-2.895927e-16</td>\n",
       "      <td>-1.651603e-31</td>\n",
       "      <td>...</td>\n",
       "      <td>7.536254e-31</td>\n",
       "      <td>5.742365e-32</td>\n",
       "      <td>-1.011808e-31</td>\n",
       "      <td>-1.944065e-31</td>\n",
       "      <td>-3.811088e-32</td>\n",
       "      <td>6.072956e-32</td>\n",
       "      <td>3.103294e-32</td>\n",
       "      <td>-1.148311e-31</td>\n",
       "      <td>-6.972519e-32</td>\n",
       "      <td>3.833123e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A. K. P.</th>\n",
       "      <td>7.434920e-02</td>\n",
       "      <td>-6.367046e-02</td>\n",
       "      <td>7.244335e-17</td>\n",
       "      <td>-9.607008e-02</td>\n",
       "      <td>-2.400424e-02</td>\n",
       "      <td>-1.959493e-16</td>\n",
       "      <td>5.168824e-16</td>\n",
       "      <td>-3.117077e-01</td>\n",
       "      <td>-7.519223e-02</td>\n",
       "      <td>-1.970802e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>6.988332e-17</td>\n",
       "      <td>-1.126544e-17</td>\n",
       "      <td>2.490298e-18</td>\n",
       "      <td>-5.793116e-19</td>\n",
       "      <td>4.949401e-18</td>\n",
       "      <td>-1.610371e-17</td>\n",
       "      <td>-2.934973e-18</td>\n",
       "      <td>1.218727e-17</td>\n",
       "      <td>1.705795e-18</td>\n",
       "      <td>-1.955307e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A. Slater</th>\n",
       "      <td>7.553439e-18</td>\n",
       "      <td>-1.005169e-16</td>\n",
       "      <td>-5.244143e-15</td>\n",
       "      <td>2.017932e-16</td>\n",
       "      <td>-3.907669e-17</td>\n",
       "      <td>-9.056838e-18</td>\n",
       "      <td>-2.364022e-15</td>\n",
       "      <td>1.072187e-15</td>\n",
       "      <td>3.681951e-16</td>\n",
       "      <td>1.050619e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>5.859407e-18</td>\n",
       "      <td>-1.052511e-17</td>\n",
       "      <td>-1.351659e-17</td>\n",
       "      <td>2.069138e-17</td>\n",
       "      <td>1.564400e-17</td>\n",
       "      <td>-7.458719e-17</td>\n",
       "      <td>-1.461191e-17</td>\n",
       "      <td>1.431483e-17</td>\n",
       "      <td>3.300193e-17</td>\n",
       "      <td>2.474723e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.B.318</th>\n",
       "      <td>-1.048089e-03</td>\n",
       "      <td>-8.738537e-02</td>\n",
       "      <td>-2.305491e-16</td>\n",
       "      <td>-7.781044e-02</td>\n",
       "      <td>7.557846e-03</td>\n",
       "      <td>6.989007e-16</td>\n",
       "      <td>1.556079e-16</td>\n",
       "      <td>1.214294e-01</td>\n",
       "      <td>-8.251057e-02</td>\n",
       "      <td>5.862595e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.683413e-16</td>\n",
       "      <td>2.615857e-17</td>\n",
       "      <td>1.188410e-18</td>\n",
       "      <td>-8.551917e-18</td>\n",
       "      <td>-1.111034e-17</td>\n",
       "      <td>8.669059e-17</td>\n",
       "      <td>1.478011e-17</td>\n",
       "      <td>-2.573022e-17</td>\n",
       "      <td>-3.223377e-17</td>\n",
       "      <td>-2.217165e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.S.</th>\n",
       "      <td>-8.940232e-02</td>\n",
       "      <td>2.904630e-01</td>\n",
       "      <td>-1.519530e-15</td>\n",
       "      <td>4.253371e-03</td>\n",
       "      <td>-2.500913e-01</td>\n",
       "      <td>-2.810551e-16</td>\n",
       "      <td>1.330744e-15</td>\n",
       "      <td>-2.066735e-03</td>\n",
       "      <td>-1.103981e-01</td>\n",
       "      <td>-6.429607e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.140033e-16</td>\n",
       "      <td>3.445979e-17</td>\n",
       "      <td>-4.799862e-17</td>\n",
       "      <td>1.133589e-16</td>\n",
       "      <td>1.401984e-17</td>\n",
       "      <td>1.052016e-17</td>\n",
       "      <td>-6.892431e-18</td>\n",
       "      <td>-4.545966e-17</td>\n",
       "      <td>-2.672037e-17</td>\n",
       "      <td>-2.981505e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               A Court of Mist and Fury (A Court of Thorns and Roses, 2)  \\\n",
       "A H Kobayashi                                       1.399516e-15           \n",
       "A. K. P.                                            7.434920e-02           \n",
       "A. Slater                                           7.553439e-18           \n",
       "A.B.318                                            -1.048089e-03           \n",
       "A.S.                                               -8.940232e-02           \n",
       "\n",
       "               A Court of Thorns and Roses (A Court of Thorns and Roses, 1)  \\\n",
       "A H Kobayashi                                       2.822698e-16              \n",
       "A. K. P.                                           -6.367046e-02              \n",
       "A. Slater                                          -1.005169e-16              \n",
       "A.B.318                                            -8.738537e-02              \n",
       "A.S.                                                2.904630e-01              \n",
       "\n",
       "               A Court of Thorns and Roses Paperback Box Set (5 books)  \\\n",
       "A H Kobayashi                                      -1.270756e-15         \n",
       "A. K. P.                                            7.244335e-17         \n",
       "A. Slater                                          -5.244143e-15         \n",
       "A.B.318                                            -2.305491e-16         \n",
       "A.S.                                               -1.519530e-15         \n",
       "\n",
       "               A Court of Wings and Ruin (A Court of Thorns and Roses, 3)  \\\n",
       "A H Kobayashi                                       1.020734e-15            \n",
       "A. K. P.                                           -9.607008e-02            \n",
       "A. Slater                                           2.017932e-16            \n",
       "A.B.318                                            -7.781044e-02            \n",
       "A.S.                                                4.253371e-03            \n",
       "\n",
       "               A Little Life  All the Light We Cannot See: A Novel  \\\n",
       "A H Kobayashi   6.168280e-17                          1.161061e-30   \n",
       "A. K. P.       -2.400424e-02                         -1.959493e-16   \n",
       "A. Slater      -3.907669e-17                         -9.056838e-18   \n",
       "A.B.318         7.557846e-03                          6.989007e-16   \n",
       "A.S.           -2.500913e-01                         -2.810551e-16   \n",
       "\n",
       "               Atomic Habits: An Easy & Proven Way to Build Good Habits & Break Bad Ones  \\\n",
       "A H Kobayashi                                       3.458629e-17                           \n",
       "A. K. P.                                            5.168824e-16                           \n",
       "A. Slater                                          -2.364022e-15                           \n",
       "A.B.318                                             1.556079e-16                           \n",
       "A.S.                                                1.330744e-15                           \n",
       "\n",
       "               Brown Bear, Brown Bear, What Do You See?  \\\n",
       "A H Kobayashi                              1.310615e-15   \n",
       "A. K. P.                                  -3.117077e-01   \n",
       "A. Slater                                  1.072187e-15   \n",
       "A.B.318                                    1.214294e-01   \n",
       "A.S.                                      -2.066735e-03   \n",
       "\n",
       "               Chicka Chicka Boom Boom (Board Book)  \\\n",
       "A H Kobayashi                         -2.895927e-16   \n",
       "A. K. P.                              -7.519223e-02   \n",
       "A. Slater                              3.681951e-16   \n",
       "A.B.318                               -8.251057e-02   \n",
       "A.S.                                  -1.103981e-01   \n",
       "\n",
       "               Demon Copperhead: A Pulitzer Prize Winner  ...  \\\n",
       "A H Kobayashi                              -1.651603e-31  ...   \n",
       "A. K. P.                                   -1.970802e-17  ...   \n",
       "A. Slater                                   1.050619e-17  ...   \n",
       "A.B.318                                     5.862595e-16  ...   \n",
       "A.S.                                       -6.429607e-16  ...   \n",
       "\n",
       "               genre_Nonfiction  genre_Personal Finance  genre_Picture Book  \\\n",
       "A H Kobayashi      7.536254e-31            5.742365e-32       -1.011808e-31   \n",
       "A. K. P.           6.988332e-17           -1.126544e-17        2.490298e-18   \n",
       "A. Slater          5.859407e-18           -1.052511e-17       -1.351659e-17   \n",
       "A.B.318           -1.683413e-16            2.615857e-17        1.188410e-18   \n",
       "A.S.              -4.140033e-16            3.445979e-17       -4.799862e-17   \n",
       "\n",
       "               genre_Picture Books  genre_Romance  genre_Self Help  \\\n",
       "A H Kobayashi        -1.944065e-31  -3.811088e-32     6.072956e-32   \n",
       "A. K. P.             -5.793116e-19   4.949401e-18    -1.610371e-17   \n",
       "A. Slater             2.069138e-17   1.564400e-17    -7.458719e-17   \n",
       "A.B.318              -8.551917e-18  -1.111034e-17     8.669059e-17   \n",
       "A.S.                  1.133589e-16   1.401984e-17     1.052016e-17   \n",
       "\n",
       "               genre_Self-improvement  genre_Spiritual Warfare  \\\n",
       "A H Kobayashi            3.103294e-32            -1.148311e-31   \n",
       "A. K. P.                -2.934973e-18             1.218727e-17   \n",
       "A. Slater               -1.461191e-17             1.431483e-17   \n",
       "A.B.318                  1.478011e-17            -2.573022e-17   \n",
       "A.S.                    -6.892431e-18            -4.545966e-17   \n",
       "\n",
       "               genre_Spirituality  genre_Thriller  \n",
       "A H Kobayashi       -6.972519e-32    3.833123e-31  \n",
       "A. K. P.             1.705795e-18   -1.955307e-17  \n",
       "A. Slater            3.300193e-17    2.474723e-17  \n",
       "A.B.318             -3.223377e-17   -2.217165e-16  \n",
       "A.S.                -2.672037e-17   -2.981505e-16  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asegurarse de que no haya NaN ni infinitos en la matriz\n",
    "user_book_genre_matrix_filled = user_book_genre_matrix_filled.replace([np.inf, -np.inf], np.nan)  # Reemplazar infs por NaN\n",
    "user_book_genre_matrix_filled = user_book_genre_matrix_filled.fillna(0)  # Reemplazar NaNs por 0\n",
    "\n",
    "# Asegurarse de que los valores son de tipo float\n",
    "user_book_genre_matrix_filled = user_book_genre_matrix_filled.astype(float)\n",
    "\n",
    "# Aplicar SVD\n",
    "U, sigma, Vt = svds(user_book_genre_matrix_filled.values, k=50)\n",
    "\n",
    "# Convertir sigma a una matriz diagonal\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruir la matriz de calificaciones\n",
    "predicted_ratings_matrix = np.dot(np.dot(U, sigma), Vt)\n",
    "\n",
    "# Convertir la matriz reconstruida en un DataFrame\n",
    "predicted_ratings_df = pd.DataFrame(predicted_ratings_matrix, \n",
    "                                    index=user_book_genre_matrix_filled.index, \n",
    "                                    columns=user_book_genre_matrix_filled.columns)\n",
    "\n",
    "# Mostrar las primeras filas de las predicciones\n",
    "predicted_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bdc61ef-ab92-4946-80e5-b03979b15116",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m train_actual \u001b[38;5;241m=\u001b[39m user_book_matrix_filled\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Calcular el RMSE en el conjunto de entrenamiento (solo libros)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE del modelo en el conjunto de entrenamiento: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_predicted_books\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mtrain_actual\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mrmse\u001b[0;34m(predicted, actual)\u001b[0m\n\u001b[1;32m      8\u001b[0m predicted_flat \u001b[38;5;241m=\u001b[39m predicted[actual \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m actual_flat \u001b[38;5;241m=\u001b[39m actual[actual \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_flat\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/Software/tf-data-science/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Software/tf-data-science/notebooks/.venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[1;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[1;32m    504\u001b[0m         )\n\u001b[0;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/Documents/Software/tf-data-science/notebooks/.venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Software/tf-data-science/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Software/tf-data-science/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Software/tf-data-science/notebooks/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# Seleccionar solo las columnas de los libros en la matriz de predicciones (excluyendo los géneros)\n",
    "book_columns = user_book_matrix_filled.columns  # Columnas correspondientes a los libros\n",
    "train_predicted_books = predicted_ratings_df[book_columns].reindex(user_book_matrix_filled.index).fillna(0).values\n",
    "\n",
    "# Calcular RMSE\n",
    "def rmse(predicted, actual):\n",
    "    # Filtrar los valores que no son 0 en la matriz real\n",
    "    predicted_flat = predicted[actual != 0]\n",
    "    actual_flat = actual[actual != 0]\n",
    "    return np.sqrt(mean_squared_error(actual_flat, predicted_flat))\n",
    "\n",
    "# Obtener las calificaciones reales y predichas del conjunto de entrenamiento\n",
    "train_actual = user_book_matrix_filled.values\n",
    "\n",
    "# Calcular el RMSE en el conjunto de entrenamiento (solo libros)\n",
    "print(f\"RMSE del modelo en el conjunto de entrenamiento: {rmse(train_predicted_books, train_actual)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb165a-4206-4fb9-8586-8ecea00e6cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las calificaciones reales y predichas del conjunto de prueba\n",
    "test_user_book_matrix = test_df.pivot_table(index='reviewer', columns='book_title', values='reviewer_rating')\n",
    "test_user_book_matrix_filled = test_user_book_matrix.fillna(0)\n",
    "test_predicted = predicted_ratings_df.reindex(test_user_book_matrix_filled.index).fillna(0)[test_user_book_matrix_filled.columns].fillna(0).values\n",
    "\n",
    "# Calcular el RMSE en el conjunto de prueba\n",
    "test_actual = test_user_book_matrix_filled.values\n",
    "print(f\"RMSE del modelo en el conjunto de prueba: {rmse(test_predicted, test_actual)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cfdd2b-a79b-43f4-b07d-d978b2c08c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma para comparar las calificaciones reales y las predichas en el conjunto de prueba\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(test_actual[test_actual != 0].flatten(), bins=50, alpha=0.5, label='Calificaciones Reales', color='blue')\n",
    "plt.hist(test_predicted[test_actual != 0].flatten(), bins=50, alpha=0.5, label='Calificaciones Predichas', color='red')\n",
    "plt.title('Distribución de Calificaciones: Reales vs Predichas (Conjunto de Prueba)')\n",
    "plt.xlabel('Calificación')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f9251-80e6-4f9e-ac45-8407c8c5a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener recomendaciones para un usuario\n",
    "def get_top_recommendations(user_id, original_ratings_matrix, predicted_ratings_matrix, num_recommendations=5):\n",
    "    # Obtener los libros que el usuario ya ha calificado\n",
    "    user_rated_books = original_ratings_matrix.loc[user_id].dropna().index.tolist()\n",
    "    \n",
    "    # Obtener las predicciones para ese usuario\n",
    "    user_predictions = predicted_ratings_matrix.loc[user_id].sort_values(ascending=False)\n",
    "    \n",
    "    # Filtrar los libros que el usuario no ha calificado\n",
    "    recommendations = user_predictions[~user_predictions.index.isin(user_rated_books)].head(num_recommendations)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Ejemplo de uso: Obtener recomendaciones para un usuario específico\n",
    "example_user = \"A H Kobayashi\"\n",
    "top_recommendations = get_top_recommendations(example_user, user_book_matrix, predicted_ratings_df)\n",
    "\n",
    "# Mostrar las recomendaciones\n",
    "print(\"Libros recomendados para A H Kobayashi:\")\n",
    "print(top_recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
